{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kahqOOp9rjx"
      },
      "source": [
        "# 1.introduction\n",
        "\n",
        "A Convolutional Neural Network for Car Classification\n",
        "\n",
        "This project uses the Stanford car dataset attmpting to train a deep learning model to classify cars. The Cars dataset contains 16,185 images of 196 classes of cars. The data is split into training samples of size 8,144 and testing samples of size 8,041. Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.\n",
        "\n",
        "The dataset is available at https://ai.stanford.edu/~jkrause/cars/car_dataset.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7SmzE06ZXhR"
      },
      "source": [
        "# 2. Prepare data\n",
        "\n",
        "The model I use will start with transfer learning to train the model. All neural network layers are fine tuned, and the last fully connected layer is entirely replaced.\n",
        "\n",
        "Dataset (196 classes):\n",
        "\n",
        "Train folder: 8144 images, avg: 41.5 images per class.\n",
        "\n",
        "Test folder: 8041 images, avg: 41.0 images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIFdlE7VDM9x",
        "outputId": "31b6996d-1ea6-4ce2-b0bf-8994df3fb3cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Projects/Car classification\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/Projects/Car classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3gTCY271nIS",
        "outputId": "b186d189-20e8-469a-881c-6ebee206741b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open stanford_car_dataset.zip, stanford_car_dataset.zip.zip or stanford_car_dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q stanford_car_dataset.zip -d ./stanford_car_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YTAcNFKBTSm"
      },
      "source": [
        "# 3. Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80Fx_Cv-Bbbk"
      },
      "source": [
        "## 3.1 Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmld6dLSZXhU",
        "outputId": "0aafc071-b188-4354-cdcc-46f484705dd3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import os\n",
        "import tqdm\n",
        "import PIL.Image as Image\n",
        "from IPython.display import display\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEGLzCXMZXhb"
      },
      "source": [
        "## 3.2 Load and transform the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qBN8afm4ZXhc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Transform the data and labels here\n",
        "# The 224x224 images are processed with random horizontal flip (random rotation or normalization can be used too)\n",
        "\n",
        "dataset_dir = \"stanford_car_dataset/car_data/car_data/\"\n",
        "\n",
        "# data transformation, can use different trasnformation or augmentation\n",
        "# note: no data augmentation for test data\n",
        "\n",
        "width, height = 224, 224\n",
        "train_tfms = transforms.Compose([transforms.Resize((width, height)),\n",
        "                                 #transforms.RandomHorizontalFlip(),\n",
        "                                 #transforms.RandomRotation(15),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])  # mean and std from imagenet dataset\n",
        "test_tfms = transforms.Compose([transforms.Resize((width, height)),\n",
        "                                 #transforms.RandomHorizontalFlip(),\n",
        "                                 #transforms.RandomRotation(15),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# create datasets\n",
        "dataset = torchvision.datasets.ImageFolder(root=dataset_dir + \"train\", transform = train_tfms)\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "dataset2 = torchvision.datasets.ImageFolder(root=dataset_dir + \"test\", transform = test_tfms)\n",
        "testloader = torch.utils.data.DataLoader(dataset2, batch_size=32, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLO9RrULZXhf"
      },
      "source": [
        "## 3.3 Train and Test the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "430hhzprZXhf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, n_epochs=5):\n",
        "\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    # set the model to train mode initially\n",
        "    model.train()\n",
        "    for epoch in tqdm.tqdm(range(n_epochs)):\n",
        "        since = time.time()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "            # get the inputs and assign them to cuda\n",
        "            inputs, labels = data\n",
        "            #inputs = inputs.to(device).half() # half precision model to quickly check\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            # torch.cuda.amp.autocast() # for half precision model\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # accumulate loss & acc\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_correct += (labels==predicted).sum().item()\n",
        "\n",
        "        epoch_duration = time.time() - since\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_acc = 100 / 32 * running_correct / len(trainloader)\n",
        "        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
        "\n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_acc)\n",
        "\n",
        "        # switch the model to eval mode to evaluate on test data\n",
        "        model.eval()\n",
        "        test_acc = eval_model(model)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        # re-set the model to train mode after validating\n",
        "        model.train()\n",
        "        scheduler.step(test_acc)\n",
        "        since = time.time()\n",
        "    print('Finished Training')\n",
        "    return model, losses, accuracies, test_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SApHdqV-ZXhi"
      },
      "source": [
        "## 3.4 Evaluate the Model on training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m7HcAWnVZXhj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def eval_model(model):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(testloader, 0):\n",
        "            images, labels = data\n",
        "            #images = images.to(device).half() # uncomment for half precision model\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_acc = 100.0 * correct / total\n",
        "    print('Accuracy of the network on the test images: %d %%' % (\n",
        "        test_acc))\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouIHQb3uJZsE"
      },
      "source": [
        "# 4. Tuning the model - AlexNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wly0BhFZJeHK"
      },
      "source": [
        "## 4.1 define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY0_fTZ8ZXhm",
        "outputId": "498a28b8-5d63-4f23-e67f-9b2c790a8994",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:00<00:00, 266MB/s]\n"
          ]
        }
      ],
      "source": [
        "NUM_CAR_CLASSES = 196\n",
        "\n",
        "# use alexnet as the base model\n",
        "model_ft_an = models.alexnet(pretrained=True)\n",
        "\n",
        "# Freeze model parameters and define the FC layer to be attached to the model,\n",
        "# loss function and the optimizer.\n",
        "\n",
        "# put the model on the GPUs\n",
        "for param in model_ft_an.parameters():\n",
        "    param.require_grad = False\n",
        "\n",
        "# replace the last fc layer with an untrained one (requires grad)\n",
        "\n",
        "num_ftrs_an = model_ft_an.classifier[6].in_features\n",
        "model_ft_an.classifier[6] = nn.Linear(num_ftrs_an, NUM_CAR_CLASSES)\n",
        "\n",
        "model_ft_an = model_ft_an.to(device)\n",
        "\n",
        "# half precision model\n",
        "# model_ft_an = model_ft_an.half()\n",
        "\n",
        "# for layer in model_ft_an.modules():\n",
        "#     if isinstance(layer, nn.BatchNorm2d):\n",
        "#         layer.float()\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft_an.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y22f6wzZJiWT"
      },
      "source": [
        "## 4.2 model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFaSvRlqZXhr",
        "outputId": "0e41f1e9-f169-4d6c-e136-ea2aa205d8c5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "model_ft_an, training_losses, training_accs, test_accs = train_model(model_ft_an, criterion, optimizer, lrscheduler, n_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGJZtLKtZXhv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plot the stats\n",
        "\n",
        "f, axarr = plt.subplots(2,2, figsize = (12, 8))\n",
        "axarr[0, 0].plot(training_losses)\n",
        "axarr[0, 0].set_title(\"Training loss, AlexNet\")\n",
        "axarr[0, 1].plot(training_accs)\n",
        "axarr[0, 1].set_title(\"Training acc, AlexNet\")\n",
        "axarr[1, 0].plot(test_accs)\n",
        "\n",
        "axarr[1, 0].set_title(\"Test acc, AlexNet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxW-YfstZXhy"
      },
      "source": [
        "## 4.3 Evaluate the model on single images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiskimFLZXhz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# tie the class indices to their names\n",
        "\n",
        "def find_classes(dir):\n",
        "    classes = os.listdir(dir)\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "classes, c_to_idx = find_classes(dataset_dir + \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flkEoZY3ZXh6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# test the model on random images\n",
        "\n",
        "# switch the model to evaluation mode to make dropout and batch norm work in eval mode\n",
        "model_ft_an.eval()\n",
        "\n",
        "# transforms for the input image\n",
        "loader = transforms.Compose([transforms.Resize((400, 400)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "image = Image.open(dataset_dir+\"test/Mercedes-Benz C-Class Sedan 2012/01977.jpg\")\n",
        "image = loader(image).float()\n",
        "image = torch.autograd.Variable(image, requires_grad=True)\n",
        "image = image.unsqueeze(0)\n",
        "image = image.cuda()\n",
        "output = model_ft_an(image)\n",
        "conf, predicted = torch.max(output.data, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6fuUhijZXh9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# get the class name of the prediction\n",
        "display(Image.open(dataset_dir+\"test/Mercedes-Benz C-Class Sedan 2012/01977.jpg\"))\n",
        "print(classes[predicted.item()], \"confidence: \", conf.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md3QyP3XvcIr"
      },
      "source": [
        "# 5. Tuning the model - ResNet34\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLCH7pdpH6zD"
      },
      "source": [
        "## 5.1 define parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOvHBnr-Hq5S"
      },
      "outputs": [],
      "source": [
        "NUM_CAR_CLASSES = 196\n",
        "\n",
        "# use resnet as the base model\n",
        "model_ft_rn = models.resnet34(pretrained=True)\n",
        "\n",
        "# Freeze model parameters and define the FC layer to be attached to the model,\n",
        "# loss function and the optimizer.\n",
        "\n",
        "# put the model on the GPUs\n",
        "for param in model_ft_rn.parameters():\n",
        "    param.require_grad = False\n",
        "\n",
        "# replace the last fc layer with an untrained one (requires grad)\n",
        "\n",
        "# resnet34\n",
        "num_ftrs_rn = model_ft_rn.fc.in_features\n",
        "model_ft_rn.fc = nn.Linear(num_ftrs_rn, NUM_CAR_CLASSES)\n",
        "\n",
        "model_ft_rn = model_ft_rn.to(device)\n",
        "\n",
        "# half precision model\n",
        "# model_ft_rn = model_ft_rn.half()\n",
        "# for layer in model_ft_rn.modules():\n",
        "#     if isinstance(layer, nn.BatchNorm2d):\n",
        "#         layer.float()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft_rn.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUsz-Tl8H__G"
      },
      "source": [
        "## 5.2 model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9Xaf2iMICcl"
      },
      "outputs": [],
      "source": [
        "model_ft_rn, training_losses, training_accs, test_accs = train_model(model_ft_rn, criterion, optimizer, lrscheduler, n_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLuozXhjKw9S"
      },
      "outputs": [],
      "source": [
        "# plot the stats\n",
        "\n",
        "f, axarr = plt.subplots(2,2, figsize = (12, 8))\n",
        "axarr[0, 0].plot(training_losses)\n",
        "axarr[0, 0].set_title(\"Training loss, ResNet34\")\n",
        "axarr[0, 1].plot(training_accs)\n",
        "axarr[0, 1].set_title(\"Training acc, ResNet34\")\n",
        "axarr[1, 0].plot(test_accs)\n",
        "\n",
        "axarr[1, 0].set_title(\"Test acc, ResNet34\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-AQThSNIGEW"
      },
      "source": [
        "## 5.3 Evaluate the model on single images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjVnOU0MKRxX"
      },
      "outputs": [],
      "source": [
        "# test the model on random images\n",
        "\n",
        "# switch the model to evaluation mode to make dropout and batch norm work in eval mode\n",
        "model_ft_rn.eval()\n",
        "\n",
        "# transforms for the input image\n",
        "loader = transforms.Compose([transforms.Resize((400, 400)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "image = Image.open(dataset_dir+\"test/Mercedes-Benz C-Class Sedan 2012/01977.jpg\")\n",
        "image = loader(image).float()\n",
        "image = torch.autograd.Variable(image, requires_grad=True)\n",
        "image = image.unsqueeze(0)\n",
        "image = image.cuda()\n",
        "output = model_ft_rn(image)\n",
        "conf, predicted = torch.max(output.data, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QzdvyiiKYSL"
      },
      "outputs": [],
      "source": [
        "# get the class name of the prediction\n",
        "display(Image.open(dataset_dir+\"test/Mercedes-Benz C-Class Sedan 2012/01977.jpg\"))\n",
        "print(classes[predicted.item()], \"confidence: \", conf.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47kLCWQQJfWm"
      },
      "source": [
        "# 6. Save and Load the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk17SMRjJokk"
      },
      "outputs": [],
      "source": [
        "PATH_an = 'car_model_an.pth'\n",
        "torch.save(model_ft_an.state_dict(), PATH_an)\n",
        "\n",
        "PATH_rn = 'car_model_an.pth'\n",
        "torch.save(model_ft_rn.state_dict(), PATH_rn)\n",
        "\n",
        "model_loaded_an = torch.load(PATH_an)\n",
        "model_loaded_rn = torch.load(PATH_rn)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
